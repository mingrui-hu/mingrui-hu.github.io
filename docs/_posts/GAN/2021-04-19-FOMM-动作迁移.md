---
layout: post
title:  "GAN Day5 动作迁移"
categories: gan
---
# 什么是动作迁移

将图片A的动作迁移至图片B上

输入：源视频/动作贞



### - 生成模型在视频动画的应用

- 动漫主播、虚拟头像
- apple 表情
- 动画制作：游戏角色动作生成/短视频内容生产

# 原理

## 1. X2FACE

Source Image -> Embeddin Net -> Embedded FACE

Driving Image -> Driving Net -> Motion Flow(像素运动量) -> Generated Output

自监督Loss: l1 loss + Identity loss(VGG face_embedding) 

Note： X2face没有使用gan

## 2. First order motion model(FOMM)

- 2D图像仿射变换
- $ \vec{q} = A\vec{p} + \vec{b}$
  - 1次线性变换+1次平移向量
  - p, q 为二维像素点
- CV 常用变换 A, b组合：Translation， Identity， Reflection， Scale， Rotate， Shear

整体概述

Step1: Keypoint Estimate 关键点检测网络：估计人物主体的运动变换

- 输入：原始图片+驱动贞

- 输出：关键点信息及关键点附近的仿射信息
  - 关键点：[B, num_kp, 2] 
  - 放射系数：[B, num_kp, 2, 2]
  - 最终在每个像素点综合num_kp关键点的雅各比矩阵得出最终的位置移动
- hourglass module(常用于目标点检测)
  - components：residual module + upsampling
  - 无监督提取/生成关键点
  - 热力图:
    - 从feature_map生成heat map:
      - 对应每一个像素点是关键点的概率
- 姿态表示: 关键点附近进行泰勒展开 ->粗略的仿射变换形式 
  - A = Jacobbin Matrix 
  - $p-p_k$
  - R: 抽象参考贞
- 从抽象参考真到原始图像真的位置关系
- 从抽象参考贞到驱动图像真的位置关系
- SparseMotion
  - 认为仿射变换可逆
  - R仅用于推导
  - 预测$T_{S<-D}(z_k)$拆分成两步：S<-R 和R<-D
  - 分别让R参与推导零阶项和一阶项
  - 矩阵求逆？

- 背景信息？

Step2: Motion Estimate

- 通过k个关键点的仿射关系确定一个确定的位置
- 对驱动图像中存在而源图中不存在的像素， 进行masking-> occulasion map

输入：

- Deformed Source: 对原图进行num_kp次变换-> s1, s2, ..., s_k + 不变的背景S0（k+1）个信息

- 高斯化生成heatmap？source/driving heatmap 相减作为输入， 代表位置差异
- ```sparse_deformed = F.grid_sample(source_repeat, sparse_motions)```

Step3: Generation Module

# 训练

- 自监督：原图/驱动图来自同一个视频
- VGG19 计算reconstruction loss
- GAN loss
- 约束： 关键点一致性约束 -> 增加关键点估计的稳定性
  - 反向扰动？如何做？

# PADDLE GAN 优化

- 多人动态
- 先进行人脸检测， 然后将人脸扣出， 然后进行FOMM， 然后填回



